{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SiameseFuse.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKwJSwt4ohEG"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Flatten,Input, Lambda, Activation, Concatenate\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "from keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "# from tensorflow.keras.preprocessing.image import image_dataset_from_directory\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# import pickle\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EDGvcx5ya0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8e0169-7e35-461c-9fd6-fac7e11e506e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISmADVlGychN"
      },
      "source": [
        "grayscale_training_data = np.load('/content/drive/My Drive/grayscale_training_data.npy')  \n",
        "thermal_training_data = np.load('/content/drive/My Drive/thermal_training_data.npy') \n",
        "grayscale_training_data = np.delete(grayscale_training_data,np.s_[5000:8186],0)\n",
        "thermal_training_data = np.delete(thermal_training_data,np.s_[5000:8186],0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPlo04KHlDeI"
      },
      "source": [
        "grayscale_test_data = np.load('/content/drive/My Drive/grayscale_test_data.npy')  \n",
        "thermal_test_data = np.load('/content/drive/My Drive/thermal_test_data.npy') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpIIY8WI5twz"
      },
      "source": [
        "# SSIM LOSS\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "lambda1 = 0\n",
        "lambda2 = 1\n",
        "lambda3 = 1\n",
        "lambda4 = 1\n",
        "def _tf_fspecial_gauss(size, sigma):\n",
        "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
        "    \"\"\"\n",
        "    x_data, y_data = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
        "\n",
        "    x_data = np.expand_dims(x_data, axis=-1)\n",
        "    x_data = np.expand_dims(x_data, axis=-1)\n",
        "\n",
        "    y_data = np.expand_dims(y_data, axis=-1)\n",
        "    y_data = np.expand_dims(y_data, axis=-1)\n",
        "\n",
        "    x = tf.constant(x_data, dtype=tf.float32)\n",
        "    y = tf.constant(y_data, dtype=tf.float32)\n",
        "\n",
        "    g = tf.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
        "    return g / tf.reduce_sum(g)\n",
        "\n",
        "\n",
        "def SSIM_(img1, img2, size=11, sigma=1.5):\n",
        "    window = _tf_fspecial_gauss(size, sigma) # window shape [size, size]\n",
        "    K1 = 0.01\n",
        "    K2 = 0.03\n",
        "    L = 1  # depth of image (255 in case the image has a differnt scale)\n",
        "    C1 = (K1*L)**2\n",
        "    C2 = (K2*L)**2\n",
        "    mu1 = tf.nn.conv2d(img1, window, strides=[1,1,1,1], padding='VALID')\n",
        "    mu2 = tf.nn.conv2d(img2, window, strides=[1,1,1,1],padding='VALID')\n",
        "    mu1_sq = mu1*mu1\n",
        "    mu2_sq = mu2*mu2\n",
        "    mu1_mu2 = mu1*mu2\n",
        "    sigma1_sq = tf.nn.conv2d(img1*img1, window, strides=[1,1,1,1],padding='VALID') - mu1_sq\n",
        "    sigma2_sq = tf.nn.conv2d(img2*img2, window, strides=[1,1,1,1],padding='VALID') - mu2_sq\n",
        "    sigma12 = tf.nn.conv2d(img1*img2, window, strides=[1,1,1,1],padding='VALID') - mu1_mu2\n",
        "\n",
        "    value = (2.0*sigma12 + C2)/(sigma1_sq + sigma2_sq + C2)\n",
        "    value = tf.reduce_mean(value)\n",
        "    return value\n",
        "\n",
        "def SSIM_LOSS(img1, img2, size=11, sigma=1.5):\n",
        "    window = _tf_fspecial_gauss(size, sigma) # window shape [size, size]\n",
        "    K1 = 0.01\n",
        "    K2 = 0.03\n",
        "    L = 1  # depth of image (255 in case the image has a differnt scale)\n",
        "    C1 = (K1*L)**2\n",
        "    C2 = (K2*L)**2\n",
        "    mu1 = tf.nn.conv2d(img1, window, strides=[1,1,1,1], padding='VALID')\n",
        "    mu2 = tf.nn.conv2d(img2, window, strides=[1,1,1,1],padding='VALID')\n",
        "    mu1_sq = mu1*mu1\n",
        "    mu2_sq = mu2*mu2\n",
        "    mu1_mu2 = mu1*mu2\n",
        "    sigma1_sq = tf.nn.conv2d(img1*img1, window, strides=[1,1,1,1],padding='VALID') - mu1_sq\n",
        "    sigma2_sq = tf.nn.conv2d(img2*img2, window, strides=[1,1,1,1],padding='VALID') - mu2_sq\n",
        "    sigma12 = tf.nn.conv2d(img1*img2, window, strides=[1,1,1,1],padding='VALID') - mu1_mu2\n",
        "\n",
        "    value = (2.0*sigma12 + C2)/(sigma1_sq + sigma2_sq + C2)\n",
        "    value = tf.reduce_mean(value)\n",
        "    return 1-value\n",
        "def correlation_coefficient_loss(y_true, y_pred):\n",
        "    x = y_true\n",
        "    y = y_pred\n",
        "    mx = K.mean(x)\n",
        "    my = K.mean(y)\n",
        "    xm, ym = x-mx, y-my\n",
        "    r_num = K.sum(tf.multiply(xm,ym))\n",
        "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
        "    r = r_num / r_den\n",
        "\n",
        "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
        "    return 1 - K.square(r)\n",
        "def loss_funct(in1,out1):\n",
        "  return (lambda1*loss_SSIM(in1,out1) + lambda2*(tf.norm(in1-out1, ord='euclidean')) + lambda3*correlation_coefficient_loss(in1,out1) +\\\n",
        "          lambda4*loss_MS_SSIM(in1, out1))\n",
        "\n",
        "def loss_MS_SSIM(in1,out1):\n",
        "  return 1-tf.image.ssim_multiscale(in1,out1,max_val=1)\n",
        "def MS_SSIM(in1,out1):\n",
        "  return tf.image.ssim_multiscale(in1,out1,max_val=1)\n",
        "\n",
        "def loss_SSIM(in1,out1):\n",
        "  return 1-tf.image.ssim(in1,out1,max_val=1)\n",
        "def tf_SSIM(in1,out1):\n",
        "  return tf.image.ssim(in1,out1,max_val=1)\n",
        "\n",
        "def SCD(img1, fus):\n",
        "    value = corr2(fus, img1)\n",
        "    tf.cast(value, tf.float32)\n",
        "    return value\n",
        "\n",
        "def corr2(a,b):\n",
        "    a = a - K.sum(a)\n",
        "    b = b - K.sum(b)\n",
        "    r = K.sum(tf.multiply(a,b)) / K.sqrt(tf.multiply(K.sum(K.square(a)) , K.sqrt(K.sum(K.square(b)))));\n",
        "    return r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cemfvLmy51xp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fb10177-5c16-4c90-afea-1dda5b086cd2"
      },
      "source": [
        "# flir dataset\n",
        "def summation(vects):\n",
        "    x, y = vects\n",
        "    return x+y\n",
        "def summation_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1)\n",
        "def create_base_network(input_shape):\n",
        "    '''Base network to be shared (eq. to feature extraction).\n",
        "    '''\n",
        "\n",
        "    \n",
        "    input = Input(shape=input_shape)\n",
        "    x = Conv2D(16, (3, 3),padding='same',kernel_initializer=\"glorot_normal\",activation='relu')(input)\n",
        "    x = Conv2D(32, (3, 3),padding='same',kernel_initializer=\"glorot_normal\",activation='relu')(x)\n",
        "    # x = Conv2D(64, (3, 3),padding='same',activation='relu')(x)\n",
        "    return Model(input, x)\n",
        "\n",
        "def decoder(input_shape):\n",
        "    input = Input(shape=input_shape)\n",
        "    # x = Conv2D(128, (3, 3),padding='same',activation='relu')(input)\n",
        "    # x = Conv2D(64, (3, 3),padding='same',activation='relu')(x)\n",
        "    x = Conv2D(32, (3, 3),padding='same',kernel_initializer=\"glorot_normal\",activation='relu')(input)\n",
        "    x = Conv2D(16, (3, 3),padding='same',kernel_initializer=\"glorot_normal\",activation='relu')(x)\n",
        "    out = Conv2D(1, (3, 3),padding='same',kernel_initializer=\"glorot_normal\",activation='relu')(x)\n",
        "    return Model(input, out)\n",
        "\n",
        "input_shape = thermal_training_data.shape[1:]\n",
        "base_network = create_base_network(input_shape)\n",
        "\n",
        "\n",
        "input_a = Input(shape=input_shape)\n",
        "input_b = Input(shape=input_shape)\n",
        "processed_a = base_network(input_a)\n",
        "processed_b = base_network(input_b)\n",
        "\n",
        "sum_shape = thermal_training_data.shape[1:]\n",
        "aa = Lambda(summation,\n",
        "                  output_shape=sum_shape)([processed_a, processed_b])\n",
        "# aa = Concatenate()([processed_a, processed_b])\n",
        "\n",
        "base_decoder_network = decoder((256,256,32))\n",
        "out1 = base_decoder_network(aa)\n",
        "out2 = base_decoder_network(aa)\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_a, input_b], outputs=[out1,out2])       \n",
        "\n",
        "\n",
        "opt = keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(loss=loss_funct,optimizer=opt,metrics=[loss_funct,MS_SSIM,tf_SSIM])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit([grayscale_training_data,thermal_training_data], [grayscale_training_data,thermal_training_data],\n",
        "                epochs=18,\n",
        "                batch_size=128,\n",
        "                shuffle=True)\n",
        "                # validation_data=([grayscale_training_data,thermal_training_data], [grayscale_training_data,thermal_training_data]))\n",
        "                # validation_data=([grayscale_test_data,thermal_test_data], [grayscale_test_data,thermal_test_data]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 (None, 256, 256, 32) 4800        input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 256, 256, 1)  0           model_1[1][0]                    \n",
            "                                                                 model_1[2][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Model)                 (None, 256, 256, 1)  14017       lambda_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 18,817\n",
            "Trainable params: 18,817\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:281: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/18\n",
            "9609/9609 [==============================] - 72s 7ms/step - loss: 1041.0811 - model_2_loss: 524.7673 - model_2_loss_funct: 511.3266 - model_2_MS_SSIM: 0.6617 - model_2_tf_SSIM: 0.6579 - model_2_loss_funct_1: 529.7545 - model_2_MS_SSIM_1: 0.6639 - model_2_tf_SSIM_1: 0.5523\n",
            "Epoch 2/18\n",
            "9609/9609 [==============================] - 57s 6ms/step - loss: 943.8902 - model_2_loss: 468.4981 - model_2_loss_funct: 471.3630 - model_2_MS_SSIM: 0.6815 - model_2_tf_SSIM: 0.7085 - model_2_loss_funct_1: 472.5272 - model_2_MS_SSIM_1: 0.7218 - model_2_tf_SSIM_1: 0.7098\n",
            "Epoch 3/18\n",
            "9609/9609 [==============================] - 57s 6ms/step - loss: 942.6864 - model_2_loss: 466.7615 - model_2_loss_funct: 471.5374 - model_2_MS_SSIM: 0.6813 - model_2_tf_SSIM: 0.7090 - model_2_loss_funct_1: 471.1491 - model_2_MS_SSIM_1: 0.7251 - model_2_tf_SSIM_1: 0.7341\n",
            "Epoch 4/18\n",
            "9609/9609 [==============================] - 58s 6ms/step - loss: 942.3618 - model_2_loss: 466.7913 - model_2_loss_funct: 471.3376 - model_2_MS_SSIM: 0.6815 - model_2_tf_SSIM: 0.7105 - model_2_loss_funct_1: 471.0240 - model_2_MS_SSIM_1: 0.7252 - model_2_tf_SSIM_1: 0.7378\n",
            "Epoch 5/18\n",
            "9609/9609 [==============================] - 57s 6ms/step - loss: 942.8632 - model_2_loss: 466.9200 - model_2_loss_funct: 471.6459 - model_2_MS_SSIM: 0.6812 - model_2_tf_SSIM: 0.7104 - model_2_loss_funct_1: 471.2174 - model_2_MS_SSIM_1: 0.7250 - model_2_tf_SSIM_1: 0.7379\n",
            "Epoch 6/18\n",
            "9609/9609 [==============================] - 57s 6ms/step - loss: 942.2472 - model_2_loss: 466.5998 - model_2_loss_funct: 471.1293 - model_2_MS_SSIM: 0.6817 - model_2_tf_SSIM: 0.7106 - model_2_loss_funct_1: 471.1179 - model_2_MS_SSIM_1: 0.7253 - model_2_tf_SSIM_1: 0.7401\n",
            "Epoch 7/18\n",
            "9609/9609 [==============================] - 57s 6ms/step - loss: 942.1717 - model_2_loss: 466.6680 - model_2_loss_funct: 471.1187 - model_2_MS_SSIM: 0.6816 - model_2_tf_SSIM: 0.7108 - model_2_loss_funct_1: 471.0531 - model_2_MS_SSIM_1: 0.7253 - model_2_tf_SSIM_1: 0.7401\n",
            "Epoch 8/18\n",
            "9609/9609 [==============================] - 58s 6ms/step - loss: 942.6894 - model_2_loss: 466.8311 - model_2_loss_funct: 471.5100 - model_2_MS_SSIM: 0.6815 - model_2_tf_SSIM: 0.7112 - model_2_loss_funct_1: 471.1793 - model_2_MS_SSIM_1: 0.7248 - model_2_tf_SSIM_1: 0.7383\n",
            "Epoch 9/18\n",
            "9609/9609 [==============================] - 58s 6ms/step - loss: 942.0036 - model_2_loss: 466.6703 - model_2_loss_funct: 471.0971 - model_2_MS_SSIM: 0.6817 - model_2_tf_SSIM: 0.7109 - model_2_loss_funct_1: 470.9065 - model_2_MS_SSIM_1: 0.7254 - model_2_tf_SSIM_1: 0.7406\n",
            "Epoch 10/18\n",
            "9609/9609 [==============================] - 58s 6ms/step - loss: 942.4002 - model_2_loss: 466.7227 - model_2_loss_funct: 471.3129 - model_2_MS_SSIM: 0.6816 - model_2_tf_SSIM: 0.7113 - model_2_loss_funct_1: 471.0874 - model_2_MS_SSIM_1: 0.7251 - model_2_tf_SSIM_1: 0.7392\n",
            "Epoch 11/18\n",
            "9609/9609 [==============================] - 58s 6ms/step - loss: 942.0120 - model_2_loss: 466.7162 - model_2_loss_funct: 471.1279 - model_2_MS_SSIM: 0.6817 - model_2_tf_SSIM: 0.7110 - model_2_loss_funct_1: 470.8841 - model_2_MS_SSIM_1: 0.7254 - model_2_tf_SSIM_1: 0.7408\n",
            "Epoch 12/18\n",
            "9609/9609 [==============================] - 58s 6ms/step - loss: 942.0385 - model_2_loss: 466.8510 - model_2_loss_funct: 471.1282 - model_2_MS_SSIM: 0.6817 - model_2_tf_SSIM: 0.7115 - model_2_loss_funct_1: 470.9103 - model_2_MS_SSIM_1: 0.7254 - model_2_tf_SSIM_1: 0.7402\n",
            "Epoch 13/18\n",
            "9609/9609 [==============================] - 58s 6ms/step - loss: 942.1238 - model_2_loss: 466.6515 - model_2_loss_funct: 471.2415 - model_2_MS_SSIM: 0.6817 - model_2_tf_SSIM: 0.7115 - model_2_loss_funct_1: 470.8822 - model_2_MS_SSIM_1: 0.7253 - model_2_tf_SSIM_1: 0.7403\n",
            "Epoch 14/18\n",
            "9609/9609 [==============================] - 58s 6ms/step - loss: 942.7197 - model_2_loss: 467.1753 - model_2_loss_funct: 471.2784 - model_2_MS_SSIM: 0.6817 - model_2_tf_SSIM: 0.7111 - model_2_loss_funct_1: 471.4412 - model_2_MS_SSIM_1: 0.7249 - model_2_tf_SSIM_1: 0.7397\n",
            "Epoch 15/18\n",
            "9609/9609 [==============================] - 58s 6ms/step - loss: 941.8305 - model_2_loss: 466.8599 - model_2_loss_funct: 471.1170 - model_2_MS_SSIM: 0.6817 - model_2_tf_SSIM: 0.7114 - model_2_loss_funct_1: 470.7134 - model_2_MS_SSIM_1: 0.7254 - model_2_tf_SSIM_1: 0.7405\n",
            "Epoch 16/18\n",
            "9609/9609 [==============================] - 58s 6ms/step - loss: 942.0222 - model_2_loss: 466.7076 - model_2_loss_funct: 471.1848 - model_2_MS_SSIM: 0.6818 - model_2_tf_SSIM: 0.7116 - model_2_loss_funct_1: 470.8373 - model_2_MS_SSIM_1: 0.7253 - model_2_tf_SSIM_1: 0.7403\n",
            "Epoch 17/18\n",
            "9609/9609 [==============================] - 58s 6ms/step - loss: 942.0139 - model_2_loss: 466.8286 - model_2_loss_funct: 471.2115 - model_2_MS_SSIM: 0.6818 - model_2_tf_SSIM: 0.7115 - model_2_loss_funct_1: 470.8024 - model_2_MS_SSIM_1: 0.7253 - model_2_tf_SSIM_1: 0.7404\n",
            "Epoch 18/18\n",
            "9609/9609 [==============================] - 58s 6ms/step - loss: 942.2188 - model_2_loss: 466.6207 - model_2_loss_funct: 471.2380 - model_2_MS_SSIM: 0.6818 - model_2_tf_SSIM: 0.7116 - model_2_loss_funct_1: 470.9809 - model_2_MS_SSIM_1: 0.7253 - model_2_tf_SSIM_1: 0.7403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FyPWTUQ83FL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb0f7683-ac6d-4872-b035-5e932ed88f8f"
      },
      "source": [
        "# save model\n",
        "model.save('dilation_layer_2_48_decode.h5')\n",
        "files.download('dilation_layer_2_48_decode.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4169453a-f4f5-414f-8156-2db8c96fbc6b\", \"dilation_layer_2_48_decode.h5\", 267232)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk1V7WOe6tgU"
      },
      "source": [
        "# run this cell only if you would like to load from a saved file \n",
        "model = keras.models.load_model('/content/drive/My Drive/dilation_layer_2_48_decode.h5', custom_objects={ 'loss_funct': loss_funct,'SSIM_':SSIM_,'MS_SSIM':MS_SSIM,'tf_SSIM':tf_SSIM})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88lQEpzSkhKv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "216d8f98-6527-4cdd-f39e-a91ac9563505"
      },
      "source": [
        "\n",
        "output = model.predict([grayscale_test_data,thermal_test_data])\n",
        "out = output[0]\n",
        "np.save('fused123.npy', out) \n",
        "files.download('fused123.npy')\n",
        "\n",
        "\n",
        "# import cv2\n",
        "# from google.colab import files\n",
        "\n",
        "# for ii in range(839):\n",
        "#   data = out[ii,:,:,0]\n",
        "#   data = data*255\n",
        "#   cv2.imwrite('fused{}.png'.format(ii+1), data)\n",
        "#   files.download('fused{}.png'.format(ii+1)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6ff453e4-2323-485c-9feb-c432774b3e89\", \"fused123.npy\", 219938944)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}